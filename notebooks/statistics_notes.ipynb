{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics\n",
    "[stats ouline from wiki](https://en.wikipedia.org/wiki/Outline_of_statistics)\n",
    "## Describing a single set of data\n",
    "\n",
    "### Central Tendencies\n",
    "* mean\n",
    "  * Sensitive to outliers\n",
    "* median\n",
    "  * Insensitive to outliers\n",
    "  * Can use Quickselect for efficient calculation.\n",
    "* Quantiles\n",
    "  * Generalization of the median\n",
    "  * represents the value less than which a certain percentile of the data lies. (The median represents a value less than which 50% of the data lies).\n",
    " \n",
    "### Dispersion\n",
    "\n",
    "* The spread of our data.\n",
    "* range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_range(x):\n",
    "    return max(x) - min(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  * range doesn't really depend on the whole data set.\n",
    "* variance\n",
    "  * More complex than range but better at describing the *spread*\n",
    "  * Has units that are the square of the original units which can be hard to intuit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def de_mean(x):\n",
    "    \"\"\"translate x by subtracting its mean (so the result has mean 0)\"\"\"\n",
    "    x_bar = mean(x)\n",
    "    return [x_i - x_bar for x_i in x]\n",
    "\n",
    "def variance(x):\n",
    "    \"\"\"assumes x has at least two elements\"\"\"\n",
    "    n = len(x)\n",
    "    deviations = de_mean(x)\n",
    "    return sum_of_squares(deviations) / (n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Standard deviation\n",
    "  * is unitless so easier to make sense of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standard_deviation(x):\n",
    "    return math.sqrt(variance(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the range and the standard deviation are heavily affected by outliers.\n",
    "\n",
    "A more robust alternative computes the difference between the 75th and 25th percentile value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interquartile_range(x):\n",
    "    return quantile(x, 0.75) - quantile(x, 0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "* **Covariance**\n",
    "  * Hard to interpret since units are a product of component units\n",
    "  * Changing the scale changes the covariance\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def covariance(x, y):\n",
    "    n = len(x)\n",
    "    return dot(de_mean(x), de_mean(y)) / (n - 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Correlation**\n",
    "  * Divides out the standard deviation of both variables\n",
    "  * Unitless \n",
    "  * lies between -1 and 1\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correlation(x,y):\n",
    "    stdev_x = standard_deviation(x)\n",
    "    stdev_y = standard_deviation(y)\n",
    "    if stdev_x > 0 and stdev_y > 0:\n",
    "        return covariance(x,y) / stdev_x / stdev_y\n",
    "    \n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson's paradox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# The MAGIC Criteria\n",
    "[source](http://drafts.jsvine.com/the-magic-criteria/)\n",
    "\n",
    "“There are several properties of data, and its analysis and presentation, that govern its persuasive force,” he writes. “We label these by the acronym MAGIC, which stands for magnitude, articulation, generality, interestingness, and credibility.” In slightly more detail:\n",
    "\n",
    "## Magnitude\n",
    "“The strength of a statistical argument is enhanced in accord with the quantitative magnitude of support for its qualitative claim.” Oversimplified: Bigger is better. Magnitude, of course, is relative. The difference between two outcomes in an experiment might seem large on its own (“effect size”) or because the intervention seemed small (“cause size”).\n",
    "\n",
    "## Articulation\n",
    "“By articulation, we refer to the degree of comprehensible detail in which conclusions are phrased.” Under another acronym, Abelson might have called this precision or detail. An argument that says, “Trains A and B run at different speeds,” is less compelling than one that says, “Train A runs faster than Train B between Chicago and New York, but slower between New York and Boston.”\n",
    "\n",
    "## Generality\n",
    "“Generality denotes the breadth of applicability of the conclusions.” One way to accrue generality: Take multiple approaches to answering the same question. Another: Apply the same approach in different contexts.\n",
    "\n",
    "## Interestingness\n",
    "“For a statistical story to be theoretically interesting, it must have the potential, through empirical analysis, to change what people believe about an important issue.” Change what people believe. About an important issue.\n",
    "\n",
    "## Credibility\n",
    "“Credibility refers to the believability of a research claim. It requires both methodological soundness, and theoretical coherence.” The burden of proof, at least at the outset, is on the investigator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Effect Size\n",
    "[wiki](https://en.wikipedia.org/wiki/Effect_size)\n",
    "* Error of effect-size\n",
    "\n",
    "> Always present effect sizes for primary outcomes...If the units of measurement are meaningful on a practical level (e.g., number of cigarettes smoked per day), then we usually prefer an unstandardized measure (regression coefficient or mean difference) to a standardized measure (r or d).\n",
    "—  L. Wilkinson and APA Task Force on Statistical Inference (1999, p. 599)\n",
    "\n",
    "* Cohen's *d*\n",
    "Cohen's d is defined as the difference between two means divided by a standard deviation for the data, i.e.\n",
    "$$\n",
    "d = \\frac{\\bar{x}_1 - \\bar{x}_2}{s}\n",
    "$$\n",
    "\n",
    "$s$ is the [pooled standard deviation](https://en.wikipedia.org/wiki/Pooled_standard_deviation)\n",
    "\n",
    "# Power analysis\n",
    "# Statistical Hypothesis testing\n",
    "# Exploratory Data Analysis\n",
    "\n",
    "The goals of EDA are to:\n",
    "* Suggest hypotheses about the causes of observed phenomena\n",
    "* Assess assumptions on which statistical inference will be based\n",
    "* Support the selection of appropriate statistical tools and techniques\n",
    "* Provide a basis for further data collection through surveys or experiments[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics\n",
    "[wiki](https://en.wikipedia.org/wiki/Summary_statistics)\n",
    "Some of the characteristics we might want to report are:\n",
    "* central tendency: Do the values tend to cluster around a particular point?\n",
    "* modes: Is there more than one cluster?\n",
    "* spread: How much variability is there in the values?\n",
    "* tails: How quickly do the probabilities drop off as we move away from the modes?\n",
    "* outliers: Are there extreme values far from the modes?\n",
    "\n",
    "Make sure you visualize your data in addition to looking at descriptive stats. [Anscombe's Quartet](https://en.wikipedia.org/wiki/Anscombe%27s_quartet) are four graphs with very different behaviors (as evidenced when graphed) yet have identical descriptive statistics.\n",
    "\n",
    "![](https://upload.wikimedia.org/wikipedia/commons/thumb/e/ec/Anscombe%27s_quartet_3.svg/638px-Anscombe%27s_quartet_3.svg.png)\n",
    "All four sets are identical when examined using simple summary statistics, but vary considerably when graphed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability mass function\n",
    "\n",
    "PMFs map each value to its probability. \n",
    "PMFs are histograms that are normalized by dividing each bin by the total number of samples.\n",
    "\n",
    "If `ts` is a series, then to get a PMF in pandas\n",
    "```python\n",
    "pmf = ts.value_counts().sort_index() / len(ts)\n",
    "```\n",
    "to plot the pmf:\n",
    "```python\n",
    "pmf.plot(kind='hist')\n",
    "```\n",
    "\n",
    "## The class size paradox (aka Friendship paradox)\n",
    "* [wiki](https://en.wikipedia.org/wiki/Friendship_paradox)\n",
    "* [original paper](http://cs.marlboro.edu/courses/spring2010/statistics/wiki/wiki.attachments/Why_Your_Friends_Have_More_Friends_Than_You_Do.pdf)\n",
    "* [class-size paradox](http://www.umasocialmedia.com/socialnetworks/glossary/class-size-paradox/)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.3.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
